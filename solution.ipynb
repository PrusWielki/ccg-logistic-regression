{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cyclic Coordinate Descent for Logistic Regression with Lasso regularization\n",
    "\n",
    "This notebook presents the implementation of Cyclic Coordinate Descent (CCD) algorithm for parameter \n",
    "estimation in regularized logistic regression with l1 (lasso) penalty and compares it with standard \n",
    "logistic regression model without regularization. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports & Consts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Add information about reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from scipy.io import arff\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONST_DATASET_DIRECTORY_PATH = \"./datasets\"\n",
    "CONST_RESuLTS_DIRECTORY_PATH = \"./results\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Find 4 datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_datasets() -> List[dict[str, pd.DataFrame]]:\n",
    "    \"\"\"Load all ARFF datasets from the datasets folder and return them as a list of polars dataframes.\"\"\"\n",
    "    datasets = []\n",
    "    for file in os.listdir(CONST_DATASET_DIRECTORY_PATH):\n",
    "        if file.endswith(\".arff\"):\n",
    "            data = arff.loadarff(f\"{CONST_DATASET_DIRECTORY_PATH}/{file}\")\n",
    "            df = pd.DataFrame(data[0])\n",
    "            datasets.append({\"name\": file.strip(\".arff\"), \"data\": df})\n",
    "    return datasets\n",
    "\n",
    "\n",
    "def load_dataset(path: str) -> pd.DataFrame:\n",
    "    \"\"\"Load a dataset from a given path and return it as a polars dataframe.\"\"\"\n",
    "    data = arff.loadarff(path)\n",
    "    return pd.DataFrame(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "\n",
    "    def __init__(\n",
    "        self, name: str, df: pd.DataFrame, preprocessing_steps: List[callable] = None\n",
    "    ):\n",
    "        \"\"\"Initialize a new dataset with a name, data, and preprocess the data resulting in two numpy arrays. X - features, and y - target.\"\"\"\n",
    "\n",
    "        self.name = name\n",
    "        self.preprocessing_steps = preprocessing_steps\n",
    "\n",
    "        self.X = df[df.columns[:-1]]\n",
    "        self.y = df[df.columns[-1]]\n",
    "\n",
    "        for step in self.preprocessing_steps:\n",
    "            self.X = step(self.X)\n",
    "\n",
    "        # Improve Logistic Regression performance by converting to numpy arrays\n",
    "        self.X = self.X.to_numpy()\n",
    "\n",
    "        # Convert the target to binary values\n",
    "        self.class_names = self.y.unique()\n",
    "\n",
    "        # To mitigate CopyOnWriteWarning\n",
    "        self.y = self.y.copy()\n",
    "        self.y[self.y == self.class_names[0]] = 0\n",
    "        self.y[self.y == self.class_names[1]] = 1\n",
    "        self.y = self.y.to_numpy()\n",
    "\n",
    "    def fill_missing_values(df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Fill the missing values in the dataframe using the mean of the column strategy.\"\"\"\n",
    "        return df.fillna(df.mean())\n",
    "\n",
    "    def remove_colinear_features(\n",
    "        df: pd.DataFrame, threshold: float = 0.8\n",
    "    ) -> pd.DataFrame:\n",
    "        \"\"\"Remove features of a dataframe that are colinear.\"\"\"\n",
    "\n",
    "        corr_matrix = df.corr().abs()\n",
    "\n",
    "        upper_tri = corr_matrix.where(\n",
    "            np.triu(np.ones(corr_matrix.shape), k=1).astype(bool)\n",
    "        )\n",
    "\n",
    "        to_drop = [\n",
    "            column for column in upper_tri.columns if any(upper_tri[column] > threshold)\n",
    "        ]\n",
    "\n",
    "        return df.drop(columns=to_drop)\n",
    "\n",
    "    def normalize(df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Normalize the features of a dataframe based on mean and standard deviation.\"\"\"\n",
    "\n",
    "        # Use the Min-Max normalization to produce features in range [0, 1]\n",
    "\n",
    "        return (df - df.min()) / (df.max() - df.min())\n",
    "\n",
    "\n",
    "class APBreastKidney(Dataset):\n",
    "    \"\"\"APBreastKidney dataset.\n",
    "    source: https://www.openml.org/search?type=data&sort=runs&id=1158&status=active\n",
    "    \"\"\"\n",
    "\n",
    "    dataset_path = f\"{CONST_DATASET_DIRECTORY_PATH}/AP_Breast_Kidney.arff\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize tha APBreastKidney dataset\"\"\"\n",
    "\n",
    "        data = load_dataset(APBreastKidney.dataset_path)\n",
    "\n",
    "        super().__init__(\n",
    "            \"APBreastKidney\",\n",
    "            data,\n",
    "            [\n",
    "                Dataset.fill_missing_values,\n",
    "                Dataset.remove_colinear_features,\n",
    "                Dataset.normalize,\n",
    "            ],\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Keep in mind removing colinear features on a dataset with couple thousands of them is relatively time consuming\n",
    "\n",
    "datasets = [APBreastKidney()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Alternatively, load all ARFF datasets from the datasets folder\n",
    "# As a result you will obtain a list Datasets objects\n",
    "\n",
    "datasets = load_datasets()\n",
    "\n",
    "preprocessing_steps = [\n",
    "    Dataset.fill_missing_values,\n",
    "    Dataset.remove_colinear_features,\n",
    "    Dataset.normalize,\n",
    "]\n",
    "\n",
    "for i in range(len(datasets)):\n",
    "    datasets[i] = Dataset(datasets[i][\"name\"], datasets[i][\"data\"], preprocessing_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LogRegCCD\n",
    "\n",
    "Implementation of regularized Logistic Regression wiht Cyclic Coordinate Descent based on the [publication](https://www.jstatsoft.org/article/view/v033i01)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Add high-level overview of the algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement it.\n",
    "\n",
    "\n",
    "class LogRegCCD:\n",
    "    \"\"\"Logistic Regression with Coordinate Cyclic Descent and Lasso Regularization.\"\"\"\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        \"\"\"Initialize the LogRegCCD model.\"\"\"\n",
    "        pass\n",
    "\n",
    "    def fit(self, X_train: np.ndarray, y_train: np.ndarray) -> None:\n",
    "        \"\"\"Fit the Logsitic Regression model on provided training features and labels.\"\"\"\n",
    "        pass\n",
    "\n",
    "    def validate(self, X_valid: np.ndarray, y_valid: np.ndarray, measure: str) -> float:\n",
    "        \"\"\"Compute the provided measure based on the validation features and labels.\"\"\"\n",
    "        pass\n",
    "\n",
    "    def predict_proba(self, X_test: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Predict the probabilities of the classes for the test features.\"\"\"\n",
    "        pass\n",
    "\n",
    "    def plot(selfl, measure: str) -> None:\n",
    "        \"\"\"Plot the evalueation measure over different values of lambda.\"\"\"\n",
    "        pass\n",
    "\n",
    "    def plot_coefficients(self) -> None:\n",
    "        \"\"\"Plot the coeefficients of the model over different values of lambda.\"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance & Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Performance and Comparison"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
