{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cyclic Coordinate Descent for Logistic Regression with Lasso regularization\n",
    "\n",
    "This notebook presents the implementation of Cyclic Coordinate Descent (CCD) algorithm for parameter \n",
    "estimation in regularized logistic regression with l1 (lasso) penalty and compares it with standard \n",
    "logistic regression model without regularization. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports & Consts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Add information about reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from scipy.io import arff\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONST_DATASET_DIRECTORY_PATH = \"./datasets\"\n",
    "CONST_RESuLTS_DIRECTORY_PATH = \"./results\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Find 4 datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_datasets() -> List[dict[str, pd.DataFrame]]:\n",
    "    \"\"\"Load all ARFF datasets from the datasets folder and return them as a list of polars dataframes.\"\"\"\n",
    "    datasets = []\n",
    "    for file in os.listdir(CONST_DATASET_DIRECTORY_PATH):\n",
    "        if file.endswith(\".arff\"):\n",
    "            data = arff.loadarff(f\"{CONST_DATASET_DIRECTORY_PATH}/{file}\")\n",
    "            df = pd.DataFrame(data[0])\n",
    "            datasets.append({\"name\": file.strip(\".arff\"), \"data\": df})\n",
    "    return datasets\n",
    "\n",
    "\n",
    "def load_dataset(path: str) -> pd.DataFrame:\n",
    "    \"\"\"Load a dataset from a given path and return it as a polars dataframe.\"\"\"\n",
    "    data = arff.loadarff(path)\n",
    "    return pd.DataFrame(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    \"\"\"Represents the dataset with the name, features, target, and preprocessing steps.\n",
    "    Features and target are available as numpy arrays after preprocessing.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, name: str, df: pd.DataFrame, preprocessing_steps: List[callable] = None\n",
    "    ):\n",
    "        \"\"\"Initialize a new dataset with a name, data, and preprocess the data resulting in two numpy arrays. X - features, and y - target.\"\"\"\n",
    "\n",
    "        self.name = name\n",
    "        self.preprocessing_steps = preprocessing_steps\n",
    "\n",
    "        self.X = df[df.columns[:-1]]\n",
    "        self.y = df[df.columns[-1]]\n",
    "\n",
    "        for step in self.preprocessing_steps:\n",
    "            self.X = step(self.X)\n",
    "\n",
    "        # Improve Logistic Regression performance by converting to numpy arrays\n",
    "        self.X = self.X.to_numpy()\n",
    "\n",
    "        # Convert the target to binary values\n",
    "        self.class_names = self.y.unique()\n",
    "\n",
    "        # To mitigate CopyOnWriteWarning\n",
    "        self.y = self.y.copy()\n",
    "        self.y[self.y == self.class_names[0]] = 0\n",
    "        self.y[self.y == self.class_names[1]] = 1\n",
    "        self.y = self.y.to_numpy()\n",
    "\n",
    "    def fill_missing_values(df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Fill the missing values in the dataframe using the mean of the column strategy.\"\"\"\n",
    "        return df.fillna(df.mean())\n",
    "\n",
    "    def remove_colinear_features(\n",
    "        df: pd.DataFrame, threshold: float = 0.8\n",
    "    ) -> pd.DataFrame:\n",
    "        \"\"\"Remove features of a dataframe that are colinear.\"\"\"\n",
    "\n",
    "        corr_matrix = df.corr().abs()\n",
    "\n",
    "        upper_tri = corr_matrix.where(\n",
    "            np.triu(np.ones(corr_matrix.shape), k=1).astype(bool)\n",
    "        )\n",
    "\n",
    "        to_drop = [\n",
    "            column for column in upper_tri.columns if any(upper_tri[column] > threshold)\n",
    "        ]\n",
    "\n",
    "        return df.drop(columns=to_drop)\n",
    "\n",
    "    def normalize(df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Normalize the features of a dataframe based on Min-Max.\"\"\"\n",
    "\n",
    "        # Use the Min-Max normalization to produce features in range [0, 1]\n",
    "\n",
    "        return (df - df.min()) / (df.max() - df.min())\n",
    "\n",
    "\n",
    "class APBreastKidney(Dataset):\n",
    "    \"\"\"APBreastKidney dataset.\n",
    "    source: https://www.openml.org/search?type=data&sort=runs&id=1158&status=active\n",
    "    \"\"\"\n",
    "\n",
    "    dataset_path = f\"{CONST_DATASET_DIRECTORY_PATH}/AP_Breast_Kidney.arff\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize tha APBreastKidney dataset\"\"\"\n",
    "\n",
    "        data = load_dataset(APBreastKidney.dataset_path)\n",
    "\n",
    "        super().__init__(\n",
    "            \"APBreastKidney\",\n",
    "            data,\n",
    "            [\n",
    "                Dataset.fill_missing_values,\n",
    "                Dataset.remove_colinear_features,\n",
    "                Dataset.normalize,\n",
    "            ],\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Keep in mind removing colinear features on a dataset with couple thousands of them is relatively time consuming\n",
    "\n",
    "datasets = [APBreastKidney()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Alternatively, load all ARFF datasets from the datasets folder\n",
    "# As a result you will obtain a list Datasets objects\n",
    "\n",
    "datasets = load_datasets()\n",
    "\n",
    "preprocessing_steps = [\n",
    "    Dataset.fill_missing_values,\n",
    "    Dataset.remove_colinear_features,\n",
    "    Dataset.normalize,\n",
    "]\n",
    "\n",
    "for i in range(len(datasets)):\n",
    "    datasets[i] = Dataset(datasets[i][\"name\"], datasets[i][\"data\"], preprocessing_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LogRegCCD\n",
    "\n",
    "Implementation of regularized Logistic Regression wiht Cyclic Coordinate Descent based on the [publication](https://www.jstatsoft.org/article/view/v033i01) (Chapter 3 is most relevant)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression\n",
    "\n",
    "Logistic Regression is a machine learning method capable of binary classification. It predicts the probability of an outcome. It's steps are as follows:\n",
    "\n",
    "Compute a linear combination of input features:\n",
    "\n",
    "$$\n",
    "z = w_0 + w_1 x_1 + w_2 x_2 + \\dots + w_n x_n = \\mathbf{w}^T \\mathbf{x} + b\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $x$ denotes input feature vector, where $x_1,...,x_n$ are the elements of that vector\n",
    "- $w$ denotes model weights vector \n",
    "- $b$ is the bias term  \n",
    "\n",
    "The output $z$ is then provided to the sigmoid function:\n",
    "\n",
    "$$\n",
    "\\sigma(z) = \\frac{1}{1 + e^{-z}}\n",
    "$$\n",
    "\n",
    "The output in range [0,1] denotes the probability that given feature vector $x$ belongs to the positive class.\n",
    "\n",
    "Prediction rule is based on the output of the sigmoid function, if it's larger than 0.5 we assign to class 1, otherwise assign to class 0.\n",
    "\n",
    "To fit the model to the training data. One needs to minimize the loss function, in this case Binary Cross-Entropy:\n",
    "\n",
    "$$\n",
    "\\mathcal{L} = -\\frac{1}{m} \\sum_{i=1}^{m} \\left[ y^{(i)} \\log \\hat{y}^{(i)} + \\left(1 - y^{(i)}\\right) \\log \\left(1 - \\hat{y}^{(i)}\\right) \\right]\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $m$ denotes the number of training examples  \n",
    "- $y^{(i)}$ is the class label \n",
    "- $\\hat{y}^{(i)}$ is the predicted probability  \n",
    "\n",
    "\n",
    "The weights of the model need to be optimized to find the proper fit, this can be achieved by standard gradient descent:\n",
    "\n",
    "$$\n",
    "w_j := w_j - \\alpha \\frac{\\partial \\mathcal{L}}{\\partial w_j}\n",
    "$$\n",
    "\n",
    "$$\n",
    "b := b - \\alpha \\frac{\\partial \\mathcal{L}}{\\partial b}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $ \\alpha $ is the learning rate, the higher the value the more aggressive weight updates  \n",
    "- $ \\frac{\\partial \\mathcal{L}}{\\partial w_j} $ is a gradient with respect to weight $ w_j $\n",
    "\n",
    "\n",
    "**Lasso Regulaization** (L1) is used to prevent overfitting, when the trained model can predict samples from the training set very well but struggles on the test set.\n",
    "\n",
    "Then the loss function becomes:\n",
    "\n",
    "$$\n",
    "\\mathcal{L}_{\\text{lasso}} = -\\frac{1}{m} \\sum_{i=1}^{m} \\left[ y^{(i)} \\log \\hat{y}^{(i)} + \\left(1 - y^{(i)}\\right) \\log \\left(1 - \\hat{y}^{(i)}\\right) \\right] + \\lambda \\sum_{j=1}^{n} |w_j|\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $ m $  is the number of training samples  \n",
    "- $ y^{(i)} $ is the class label\n",
    "- $ \\hat{y}^{(i)} $ is the predicted probability \n",
    "- $ \\lambda $ denotes regularization strength \n",
    "\n",
    "In essence during the training process, the model will also minizem the absolute sum of the coefficients in addition to the loss function\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Add high-level overview of the algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogRegCCD:\n",
    "    \"\"\"Logistic Regression with Coordinate Cyclic Descent and Lasso Regularization.\"\"\"\n",
    "\n",
    "    # TODO: Implement it\n",
    "    def __init__(self) -> None:\n",
    "        \"\"\"Initialize the LogRegCCD model.\"\"\"\n",
    "        pass\n",
    "\n",
    "    def fit(self, X_train: np.ndarray, y_train: np.ndarray) -> None:\n",
    "        \"\"\"Fit the Logsitic Regression model on provided training features and labels.\"\"\"\n",
    "        pass\n",
    "\n",
    "    def validate(self, X_valid: np.ndarray, y_valid: np.ndarray, measure: str) -> float:\n",
    "        \"\"\"Compute the provided measure based on the validation features and labels.\"\"\"\n",
    "        pass\n",
    "\n",
    "    def predict_proba(self, X_test: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Predict the probabilities of the classes for the test features.\"\"\"\n",
    "        pass\n",
    "\n",
    "    def plot(selfl, measure: str) -> None:\n",
    "        \"\"\"Plot the evalueation measure over different values of lambda.\"\"\"\n",
    "        pass\n",
    "\n",
    "    def plot_coefficients(self) -> None:\n",
    "        \"\"\"Plot the coeefficients of the model over different values of lambda.\"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance & Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Performance and Comparison"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
